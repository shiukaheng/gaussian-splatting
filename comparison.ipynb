{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heng/miniconda3/envs/gsn/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/heng/miniconda3/envs/gsn/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/heng/miniconda3/envs/gsn/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "('127.0.0.1', 6009)\n"
     ]
    }
   ],
   "source": [
    "from gaussian_renderer import network_gui\n",
    "from sgs2.gaussian import GaussianModel\n",
    "from sgs2.scene import Scene\n",
    "from sgs2.trainers.grid_trainer import GridTrainer\n",
    "from sgs2.trainers.simple_trainer import SimpleTrainer\n",
    "from sgs2.evaluation import evaluate_scene\n",
    "import os\n",
    "network_gui.init(\"127.0.0.1\", 6009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iteration_callback(scene, folder_path=\"./output\", save_interval=100, name=\"gaussian_model\"):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    def iteration_callback(iteration, n_gauss, mem_use, model=None):\n",
    "        if model and (iteration % save_interval == 0):\n",
    "            model_path = os.path.join(folder_path, f\"{name}_{iteration}\")\n",
    "            print(f\"Saving model at iteration {iteration} to {model_path}\")\n",
    "            model.export_for_sibr(scene, model_path)\n",
    "    return iteration_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1: Train scene\n",
    "- Method 1: Simple trainer (10K iterations)\n",
    "- Method 2: Grid trainer, no loss mask (10K iterations)\n",
    "- Method 3: Grid trainer, with loss mask (10K iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train scene\n",
    "train_scene = Scene(source_path=\"./datasets/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "model = GaussianModel.create_from_scene(train_scene)\n",
    "simple_trainer = SimpleTrainer(iterations=10000, iteration_callback=make_iteration_callback(train_scene, name=\"train_scene_simple\", save_interval=1000))\n",
    "simple = simple_trainer.train(train_scene, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GaussianModel.create_from_scene(train_scene)\n",
    "grid_trainer = GridTrainer(iterations=10000, network_gui=True, clean_chunk_edges=True, chunk_loss_masking=False)\n",
    "grid = grid_trainer.train(train_scene, grid_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.export_for_sibr(train_scene, \"./output/train_scene_grid_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading camera 346/346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heng/miniconda3/envs/gsn/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 346 Train Cameras at scale 1.0\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  507378\n"
     ]
    }
   ],
   "source": [
    "# Now, we train for \"./datasets/alleyds/\"\n",
    "alley_scene = Scene(source_path=\"./datasets/alleyds/\")\n",
    "alley_model = GaussianModel.create_from_scene(alley_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using simple trainer\n",
    "simple_trainer = SimpleTrainer(iterations=10000, iteration_callback=make_iteration_callback(alley_scene, name=\"alley_scene_simple\", save_interval=1000))\n",
    "simple = simple_trainer.train(alley_scene, alley_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points at initialisation :  507378\n",
      "Pre-training gaussians...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing visibility...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training submodel 1/7...\n",
      "Filtered cameras from 346 to 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:45<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training submodel 2/7...\n",
      "Filtered cameras from 346 to 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:26<00:00, 48.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training submodel 3/7...\n",
      "Filtered cameras from 346 to 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:19<00:00, 71.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training submodel 4/7...\n",
      "Filtered cameras from 346 to 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:22<00:00, 70.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training submodel 5/7...\n",
      "No cameras meet the visibility threshold of 0.05\n",
      "Training submodel 6/7...\n",
      "No cameras meet the visibility threshold of 0.05\n",
      "Training submodel 7/7...\n",
      "No cameras meet the visibility threshold of 0.05\n",
      "Combining gaussians...\n",
      "Done.\n",
      "Creating output folder at /home/heng/Documents/GitHub/gaussian-splatting/output/alley_scene_grid_loss_masking_10000\n"
     ]
    }
   ],
   "source": [
    "# Train with grid, without chunk loss masking\n",
    "grid_model = GaussianModel.create_from_scene(alley_scene)\n",
    "grid_trainer = GridTrainer(iterations=10000, network_gui=True, clean_chunk_edges=True, chunk_loss_masking=True)\n",
    "grid = grid_trainer.train(alley_scene, grid_model)\n",
    "grid.export_for_sibr(alley_scene, \"./output/alley_scene_grid_loss_masking_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with grid, without chunk loss masking\n",
    "grid_model = GaussianModel.create_from_scene(alley_scene)\n",
    "grid_trainer = GridTrainer(iterations=10000, network_gui=True, clean_chunk_edges=True, chunk_loss_masking=False)\n",
    "grid = grid_trainer.train(alley_scene, grid_model)\n",
    "grid.export_for_sibr(alley_scene, \"./output/alley_scene_grid_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with grid, with chunk loss masking\n",
    "grid_model = GaussianModel.create_from_scene(alley_scene)\n",
    "grid_trainer = GridTrainer(iterations=10000, network_gui=True, clean_chunk_edges=True, chunk_loss_masking=True)\n",
    "grid = grid_trainer.train(alley_scene, grid_model)\n",
    "grid.export_for_sibr(alley_scene, \"./output/alley_scene_grid_10000_chunk_masking\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
